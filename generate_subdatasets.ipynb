{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df = pd.read_csv('data/species_180.csv', index_col=0)\n",
    "BSP_df = pd.read_csv('data/BrazilianScientificProduction.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['spores 1d', 'spores 2d', 'pileus width', 'stipes long', 'stipes thick']\n",
    "measure_cols = [col + ' measure' for col in cols]\n",
    "bsp_cols = BSP_df.columns[2:]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "  # process NaN -> and get appears of boundaries from string\n",
    "  species_df[col] = species_df[col].apply(lambda x: '[\\'0\\', \\'0\\']' if type(x) == float else x).apply(lambda x: re.sub(r'[\\(\\)]', r'', re.sub(r'\\([0-9.]+|[0-9.]+\\)', r'', '-'.join(re.sub('[\\[\\]\\']', r'', x).split(',')))))\n",
    "  species_df[col] = species_df[col].apply(lambda x: re.findall(r'[0-9.]+', ' '.join(x.split('-')).strip()))\n",
    "  species_df[col] = species_df[col].apply(lambda x: np.array([float(x[0]), float(x[1])]) if len(x) >= 2 else (np.array([float(x[0]), float(x[0])]) if len(x) == 1 else np.array([0., 0.])))\n",
    "\n",
    "for col in bsp_cols:\n",
    "  # process NaN -> and get appears of boundaries from string\n",
    "  BSP_df[col] = BSP_df[col].apply(lambda x: '[\\'0\\', \\'0\\']' if type(x) == float else x).apply(lambda x: re.sub(r'[\\(\\)]', r'', re.sub(r'\\([0-9.]+|[0-9.]+\\)', r'', '-'.join(re.sub('[\\[\\]\\']', r'', x).split(',')))))\n",
    "  BSP_df[col] = BSP_df[col].apply(lambda x: re.findall(r'[0-9.]+', ' '.join(x.split('-')).strip()))\n",
    "  BSP_df[col] = BSP_df[col].apply(lambda x: np.array([float(x[0]), float(x[1])]) if len(x) >= 2 else (np.array([float(x[0]), float(x[0])]) if len(x) == 1 else np.array([0., 0.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(dataset, d_cols, top_most_group_num, group_col, top_most_col, m_cols=None):\n",
    "  dataset_a, dataset_b = dataset.copy(), dataset.copy()\n",
    "  dataset_a[d_cols] = dataset[d_cols].apply(lambda x: x.apply(lambda x: x[0]), axis=1).to_numpy()\n",
    "  dataset_b[d_cols] = dataset[d_cols].apply(lambda x: x.apply(lambda x: x[1]), axis=1).to_numpy()\n",
    "  if m_cols:\n",
    "    dataset_a[d_cols] *= dataset[m_cols].to_numpy()\n",
    "    dataset_b[d_cols] *= dataset[m_cols].to_numpy()\n",
    "\n",
    "  clusters = dataset_a.groupby(by=group_col).count()[d_cols[0]].sort_values(ascending=False)[:top_most_group_num].index.to_list()\n",
    "  dataset_a = dataset_a[dataset_a[top_most_col].isin(clusters)].reset_index(drop=True)\n",
    "  dataset_b = dataset_b[dataset_b[top_most_col].isin(clusters)].reset_index(drop=True)\n",
    "\n",
    "  real_clusters = []\n",
    "  for target in dataset_a[top_most_col].unique():\n",
    "    real_clusters.append(set(dataset_a[dataset_a[top_most_col] == target].index))\n",
    "\n",
    "  data = np.hstack([dataset_a[d_cols].to_numpy(), dataset_b[d_cols].to_numpy()])\n",
    "  return [data, real_clusters, top_most_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for i in range(3, 8):\n",
    "  datasets.append([*generate_dataset(species_df, cols, i, 'genera', 'genera', m_cols=measure_cols), 'Fungi_genera_' + str(i)])\n",
    "\n",
    "for i in range(3, 6):\n",
    "  datasets.append([*generate_dataset(BSP_df, bsp_cols, i, 'GRANDE-AREA-PREDOMINANTE', 'GRANDE-AREA-PREDOMINANTE'), 'BSP_GAP_' + str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    if not os.path.exists(\"subdatasets/\" + dataset[-1]):\n",
    "        os.mkdir(\"subdatasets/\" + dataset[-1])\n",
    "    np.save(\"subdatasets/\" + dataset[-1] + '/data', dataset[0])\n",
    "    with open('subdatasets/{}/real_clusters.txt'.format(dataset[-1]), 'w') as fp:\n",
    "        for cluster in dataset[1]:\n",
    "            # write each cluster on a new line\n",
    "            fp.write(\", \".join(map(str, cluster)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
